{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from tensorflow.keras.layers import (BatchNormalization, Bidirectional,\n",
    "                                     Dropout, Dense, LSTM)\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import random\n",
    "import pickle\n",
    "import joblib\n",
    "import bz2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dictionary for \"data\" matrix column indexing\n",
    "COL = {\n",
    "    'index': 0, 'pdb': 1, 'chain': 2, 'number': 3, 'residue': 4, 'A': 5,\n",
    "    'R': 6, 'N': 7, 'D': 8, 'C': 9, 'Q': 10, 'E': 11, 'G': 12, 'H': 13,\n",
    "    'I': 14, 'L': 15, 'K': 16, 'M': 17, 'F': 18, 'P': 19, 'S': 20, 'T': 21,\n",
    "    'W': 22, 'Y': 23, 'V': 24, 'ss8_B': 25, 'ss8_E': 26, 'ss8_G': 27,\n",
    "    'ss8_H': 28, 'ss8_I': 29, 'ss8_C': 30, 'ss8_S': 31, 'ss8_T': 32,\n",
    "    'ss3_C': 33, 'ss3_E': 34, 'ss3_H': 35, 'Steric Param': 36, 'Polarity': 37,\n",
    "    'Volume': 38, 'Hydrophobicity': 39, 'Isoelectric Pt': 40, 'Helix Prob': 41,\n",
    "    'Sheet Prob': 42, 'SASA': 43, 'phi': 44, 'psi': 45, 'omega': 46,\n",
    "    'theta': 47, 'tau': 48, 'CACN': 49, 'CNCA': 50, 'NCAC': 51, 'D:C-N': 52,\n",
    "    'D:N-CA': 53, 'D:CA-C': 54,\n",
    "    # Function \"data_augmentation\" generated columns\n",
    "    # sine / cosine of target dihedral angles\n",
    "    'sin(phi)': 55, 'cos(phi)': 56, 'sin(psi)': 57, 'cos(psi)': 58,\n",
    "    'sin(theta)': 59, 'cos(theta)': 60, 'sin(tau)': 61, 'cos(tau)': 62,\n",
    "    # Position flag class variables\n",
    "    'position_flag': 63, 'pfc_start': 64, 'pfc_middle': 65, 'pfc_end': 66,\n",
    "    # One Hot Encoded residues\n",
    "    'aa_A': 67, 'aa_C': 68, 'aa_D': 69, 'aa_E': 70, 'aa_F': 71, 'aa_G': 72,\n",
    "    'aa_H': 73, 'aa_I': 74, 'aa_K': 75, 'aa_L': 76, 'aa_M': 77, 'aa_N': 78,\n",
    "    'aa_P': 79, 'aa_Q': 80, 'aa_R': 81, 'aa_S': 82, 'aa_T': 83, 'aa_V': 84,\n",
    "    'aa_W': 85, 'aa_Y': 86\n",
    "}\n",
    "\n",
    "# Dict to map 1 letter res codes to respective int values for One Hot Encoding\n",
    "AA_MAP = {\n",
    "    'A': 0, 'C': 1, 'D': 2, 'E': 3, 'F': 4, 'G': 5, 'H': 6, 'I': 7, 'K': 8,\n",
    "    'L': 9, 'M': 10, 'N': 11, 'P': 12, 'Q': 13, 'R': 14, 'S': 15, 'T': 16,\n",
    "    'V': 17, 'W': 18, 'Y': 19\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(COL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(AA_MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(data):\n",
    "    \"\"\"\n",
    "    Reads in and modifies data loaded from a prespecified file as numpy array.\n",
    "    This function will contain any feature engineering steps desired.\n",
    "\n",
    "    Args:\n",
    "        data: numpy array with predefined protein structure prediction data.\n",
    "\n",
    "    Returns:\n",
    "        numpy array: returns engineered data array with updated information for\n",
    "            structure prediction.\n",
    "\n",
    "    NOTE: Any column added to the array for feature engineering will have\n",
    "        to be added to the relevant column list in the \"split_data\" function.\n",
    "    \"\"\"\n",
    "    print(data.shape)\n",
    "    # Fill NA values for neural network training\n",
    "    data[data == 'nan'] = 0\n",
    "\n",
    "    # Set sine and cosine of dihedral angles for more accurate predictions\n",
    "    data = np.hstack((\n",
    "        data,\n",
    "        np.sin(data[:, COL['phi']].astype(float) *\n",
    "               np.pi / 180).reshape(-1, 1),\n",
    "        np.cos(data[:, COL['phi']].astype(float) *\n",
    "               np.pi / 180).reshape(-1, 1),\n",
    "        np.sin(data[:, COL['psi']].astype(float) *\n",
    "               np.pi / 180).reshape(-1, 1),\n",
    "        np.cos(data[:, COL['psi']].astype(float) *\n",
    "               np.pi / 180).reshape(-1, 1),\n",
    "        np.sin(data[:, COL['theta']].astype(float) *\n",
    "               np.pi / 180).reshape(-1, 1),\n",
    "        np.cos(data[:, COL['theta']].astype(float) *\n",
    "               np.pi / 180).reshape(-1, 1),\n",
    "        np.sin(data[:, COL['tau']].astype(float) *\n",
    "               np.pi / 180).reshape(-1, 1),\n",
    "        np.cos(data[:, COL['tau']].astype(float) *\n",
    "               np.pi / 180).reshape(-1, 1),\n",
    "    ))\n",
    "    print(data.shape)\n",
    "    \n",
    "    # Designate position flag class: 0 at start, 2 at end, 1 in between\n",
    "    conditions = [data[:, COL['phi']] == 0, data[:, COL['psi']] == 0]\n",
    "    classes = [0, 2]\n",
    "    data = np.hstack((\n",
    "        data,\n",
    "        np.select(conditions, classes, default=1).reshape(-1, 1)\n",
    "    ))\n",
    "\n",
    "    print(data.shape)\n",
    "    \n",
    "    # Create and append One Hot Encoder columns for position flag\n",
    "    pfc = data[:, -1].astype(int)\n",
    "    ohef_matrix = np.zeros((pfc.size, pfc.max() + 1))\n",
    "    ohef_matrix[np.arange(pfc.size), pfc] = 1\n",
    "    data = np.hstack((\n",
    "        data,\n",
    "        ohef_matrix\n",
    "    ))\n",
    "\n",
    "    print(data.shape)\n",
    "#     sol={'A':'0','B':'-1','C':'-2', 'D':'-3', 'E':'-4'}\n",
    "#     #data[:, COL[\"residue\"]].replace(sol)\n",
    "    print(data[:, COL[\"residue\"]])\n",
    "    # Create and append One Hot Encoder columns for residues\n",
    "    \n",
    "#     aa = np.array([AA_MAP[a] for a in data[:, COL[\"residue\"]]]).astype(int)\n",
    "#     ohef_matrix = np.zeros((aa.size, aa.max()+1))\n",
    "#     ohef_matrix[np.arange(aa.size), aa] = 1\n",
    "#     data = np.hstack((\n",
    "#         data,\n",
    "#         ohef_matrix\n",
    "#     ))\n",
    "    print(data.shape)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. -1.  1. ...  0.  0.  0.]\n",
      " [-1. -1.  0. ...  0.  0.  0.]\n",
      " [-3. -3. -3. ...  0.  0.  0.]\n",
      " ...\n",
      " [-3. -3. -4. ...  0.  0.  0.]\n",
      " [-1. -3. -2. ...  0.  0.  0.]\n",
      " [-1. -2. -3. ...  0.  0.  0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PSPD = np.loadtxt('C:/Users/Pradeep Kumar Yadav/Documents/LSTM/LSTM/complete/1ELKA_final_input.npy')\n",
    "print(PSPD)\n",
    "len(PSPD)\n",
    "#target=pd.read_csv('C:/Users/Pradeep Kumar Yadav/Documents/LSTM/LSTM/complete/1ELKA.csv')\n",
    "#data = target.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153, 62)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PSPD.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153, 62)\n",
      "(153, 70)\n",
      "(153, 71)\n",
      "(153, 74)\n",
      "[-1. -4. -3. -2. -1. -3. -3. -3. -3. -1. -1. -3. -1. -3. -3.  1. -2. -4.\n",
      " -3. -1. -1.  0. -2.  0. -2. -3. -1. -4. -4. -3. -2. -2. -3. -2. -4. -2.\n",
      " 10. -4. -1. -1. -3. -1. -1. -4. -4. -3. -3. -4. -4. -1. -1. -4. -1. -1.\n",
      " -4. -4. -4. -2. -1. -3. -3. -4. -3. -3. -4. -4. -1. -2. -2.  1. -2. -1.\n",
      " -1. -2. -4. -1. 10. -1. -4. -3. 10. -3. -3. -4. -3. -4. -1. -2. -1.  4.\n",
      " -1. -4. -4. -3. -1. -4. -3. -1. -2. -1. -4.  1. -2. -1. -3. -4. -3. -3.\n",
      " -3. -3. -1. -1. -1. -3. -4. -4. -1. -2. -1. -2. -2. -3. -1. -3. -1. -4.\n",
      " -1. -3. -4. -1. -1. -3. -2. -2. -1. -3. -1. -1.  3. -1. -3. -4. -4. -2.\n",
      " -4. -4. -4. -3. -2. -4. -3. -3. -2.]\n",
      "(153, 74)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-59c9878b5994>:18: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  data[data == 'nan'] = 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(153, 74)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dy=data_augmentation(PSPD)\n",
    "dy.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "-1.0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-880db7129924>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mAA_MAP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-880db7129924>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mAA_MAP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: -1.0"
     ]
    }
   ],
   "source": [
    " aa = np.array([AA_MAP[a] for a in dy[:, 4]]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data):\n",
    "    \"\"\"\n",
    "    Takes engineered 'data' matrix and creates training and testing variables\n",
    "    for model training and evaluation.\n",
    "\n",
    "    Args:\n",
    "        data: numpy array with predefined protein structure prediction data.\n",
    "\n",
    "    Returns:\n",
    "        dictionary: returns dictionary with relevant variables for model\n",
    "            training and evaluation.\n",
    "    \"\"\"\n",
    "\n",
    "    # If you would like to evaluate the model on a chain within the 'data' var,\n",
    "    # Extract the chain in order to attempt to predict on unseen data\n",
    "    # data = data[~((data[:, 1] == '1YQ3') & (data[:, 2] == 'C'))]\n",
    "\n",
    "    # Array columns to be used as features for LSTM model\n",
    "    window_cols = [\n",
    "        'index', 'A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', 'L', 'K',\n",
    "        'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V', 'ss8_B', 'ss8_E', 'ss8_G',\n",
    "        'ss8_H', 'ss8_I', 'ss8_C', 'ss8_S', 'ss8_T', 'ss3_C', 'ss3_E', 'ss3_H',\n",
    "        'Steric Param', 'Polarity', 'Volume', 'Hydrophobicity',\n",
    "        'Isoelectric Pt', 'Helix Prob', 'Sheet Prob', 'SASA', 'pfc_start',\n",
    "        'pfc_middle', 'pfc_end', 'aa_A', 'aa_C', 'aa_D', 'aa_E', 'aa_F',\n",
    "        'aa_G', 'aa_H', 'aa_I', 'aa_K', 'aa_L', 'aa_M', 'aa_N', 'aa_P',\n",
    "        'aa_Q', 'aa_R', 'aa_S', 'aa_T', 'aa_V', 'aa_W', 'aa_Y',\n",
    "        'position_flag'\n",
    "    ]\n",
    "\n",
    "    # Array columns to be used as targets for LSTM model\n",
    "    y_cols = [\n",
    "        'sin(phi)', 'cos(phi)', 'sin(psi)', 'cos(psi)', 'sin(theta)',\n",
    "        'cos(theta)', 'sin(tau)', 'cos(tau)', 'CACN', 'CNCA', 'NCAC',\n",
    "        'D:C-N', 'D:N-CA', 'D:CA-C'\n",
    "    ]\n",
    "\n",
    "    # Reform data to take only desired columns\n",
    "    all_cols = [COL[name] for name in window_cols + y_cols]\n",
    "    \n",
    "    print(len(all_cols))\n",
    "    data = data[:, all_cols].astype(float)\n",
    "\n",
    "    # Scale PSSM values of whole population\n",
    "    pssm_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    data[:, 1:21] = pssm_scaler.fit_transform(data[:, 1:21])\n",
    "\n",
    "    # Scale physical property values of whole population\n",
    "    pp_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    data[:, 32:40] = pp_scaler.fit_transform(data[:, 32:40])\n",
    "\n",
    "    # Randomly generate test protein numbers\n",
    "    num_chains = len(np.unique(data[:, 0]))\n",
    "    test_num = int(num_chains * 0.10)\n",
    "    random.seed(6)\n",
    "    r = range(num_chains)\n",
    "    test_proteins = random.sample(r, test_num)\n",
    "\n",
    "    # Position variables for intuitive indexing of features and targets\n",
    "    feature_end = len(window_cols) - 1\n",
    "    target_start = len(window_cols)\n",
    "\n",
    "    # Create training and testing variables for model generation\n",
    "    train_data = data[~np.isin(data[:, 0].astype(int), test_proteins)]\n",
    "    test_data = data[np.isin(data[:, 0].astype(int), test_proteins)]\n",
    "    x_train = train_data[:, 1:feature_end]\n",
    "    y_train = train_data[:, target_start:]\n",
    "    x_test = test_data[:, 1:feature_end]\n",
    "    y_test = test_data[:, target_start:]\n",
    "\n",
    "    return {\n",
    "        'x_cols': window_cols[1:-1],\n",
    "        'y_cols': y_cols,\n",
    "        'x_train': x_train.reshape(x_train.shape[0], 1, x_train.shape[1]),\n",
    "        'y_train': y_train,\n",
    "        'x_test': x_test.reshape(x_test.shape[0], 1, x_test.shape[1]),\n",
    "        'y_test': y_test,\n",
    "        'pssm_scaler': pssm_scaler,\n",
    "        'pp_scaler': pp_scaler\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 74 is out of bounds for axis 1 with size 74",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-7766b4d02fba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msplit_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-45-d1d5ddec92df>\u001b[0m in \u001b[0;36msplit_data\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_cols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;31m#     # Scale PSSM values of whole population\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 74 is out of bounds for axis 1 with size 74"
     ]
    }
   ],
   "source": [
    "dx=split_data(dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(training_vars):\n",
    "    \"\"\"\n",
    "    Trains model for predictions on sine and cosine of dihedral angles, bond\n",
    "    angles and bond distances. Returns trained model for use on further\n",
    "    predictions and 'target_scaler' var to transform future predictions based\n",
    "    on whole population statistics.\n",
    "\n",
    "    Args:\n",
    "        training_vars: dictionary with train / test variables for model\n",
    "            utilization and statistics.\n",
    "\n",
    "    Returns:\n",
    "        model: returns trained model for target prediction on unknown proteins.\n",
    "        scaler: returns target_scaler for transformation of bond angle and bond\n",
    "            distance predictions\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract train / test variables for model training and evaluation\n",
    "    x_train = training_vars['x_train']\n",
    "    y_train = training_vars['y_train']\n",
    "    x_test = training_vars['x_test']\n",
    "    y_test = training_vars['y_test']\n",
    "    pssm_scaler = training_vars['pssm_scaler']\n",
    "    pp_scaler = training_vars['pp_scaler']\n",
    "\n",
    "    # Set vars for model input / output dimensions\n",
    "    pred_num = y_train.shape[1]\n",
    "    feat_num = x_train.shape[2]\n",
    "    time_steps = x_train.shape[1]\n",
    "\n",
    "    # Set vars for feature and target data for notification\n",
    "    x_cols = training_vars['x_cols']\n",
    "    y_cols = training_vars['y_cols']\n",
    "\n",
    "    # Notify features used and targets to be predicted\n",
    "    print(\n",
    "        f'''\n",
    "\\nPredicting target:\\t{target}\\n\n",
    "\\nTraining on dataset with {feat_num} features:\n",
    "{', '.join(x_cols)}\\n\n",
    "Predicting targets:\n",
    "{', '.join(y_cols)}\\n\n",
    "'''\n",
    "    )\n",
    "\n",
    "    # Scale bond angles and distances for more accurate prediction\n",
    "    target_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    y_train[:, 8:] = target_scaler.fit_transform(y_train[:, 8:])\n",
    "\n",
    "    # Define model to predict sin/cos of dihedrals and bond angle/distance\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(256, input_shape=(time_steps, feat_num))))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(128, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    # model.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "    # model.add(BatchNormalization())\n",
    "    model.add(Dense(pred_num, kernel_initializer='normal', activation='tanh'))\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "\n",
    "    # Set early stopping mechanism which triggers upon increase in val_loss\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "\n",
    "    # Fit model and save predictions for x_test data in 'pred' var\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=100,\n",
    "        verbose=1,\n",
    "        callbacks=[es]\n",
    "    )\n",
    "    model.summary()\n",
    "    pred = model.predict(x_test)\n",
    "    \n",
    "    # Set variables for sine and cosine of dihedral angles\n",
    "    sin_phi = pred[:, 0]\n",
    "    cos_phi = pred[:, 1]\n",
    "    sin_psi = pred[:, 2]\n",
    "    cos_psi = pred[:, 3]\n",
    "    sin_theta = pred[:, 4]\n",
    "    cos_theta = pred[:, 5]\n",
    "    sin_tau = pred[:, 6]\n",
    "    cos_tau = pred[:, 7]\n",
    "\n",
    "    # Set variables for predicted values\n",
    "    pred_phi = np.arctan2(sin_phi, cos_phi) * 180 / np.pi\n",
    "    pred_psi = np.arctan2(sin_psi, cos_psi) * 180 / np.pi\n",
    "    pred_theta = np.arctan2(sin_theta, cos_theta) * 180 / np.pi\n",
    "    pred_tau = np.arctan2(sin_tau, cos_tau) * 180 / np.pi\n",
    "    unscaled_features = target_scaler.inverse_transform(pred[:, 8:])\n",
    "    pred_cacn = unscaled_features[:, 0]\n",
    "    pred_cnca = unscaled_features[:, 1]\n",
    "    pred_ncac = unscaled_features[:, 2]\n",
    "    pred_cn = unscaled_features[:, 3]\n",
    "    pred_nca = unscaled_features[:, 4]\n",
    "    pred_cac = unscaled_features[:, 5]\n",
    "\n",
    "    # Set variables for true values\n",
    "    true_phi = np.arctan2(y_test[:, 0], y_test[:, 1]) * 180 / np.pi\n",
    "    true_psi = np.arctan2(y_test[:, 2], y_test[:, 3]) * 180 / np.pi\n",
    "    true_theta = np.arctan2(y_test[:, 4], y_test[:, 5]) * 180 / np.pi\n",
    "    true_tau = np.arctan2(y_test[:, 6], y_test[:, 7]) * 180 / np.pi\n",
    "    true_cacn = y_test[:, 8]\n",
    "    true_cnca = y_test[:, 9]\n",
    "    true_ncac = y_test[:, 10]\n",
    "    true_cn = y_test[:, 11]\n",
    "    true_nca = y_test[:, 12]\n",
    "    true_cac = y_test[:, 13]\n",
    "\n",
    "    # Set variables for MAE values based on predicted and true values\n",
    "    phi_mae = np.abs(true_phi - pred_phi)\n",
    "    phi_mae = np.mean(np.array([x if x <= 180 else 360 - x for\n",
    "                                x in phi_mae]))\n",
    "    psi_mae = np.abs(true_psi - pred_psi)\n",
    "    psi_mae = np.mean(np.array([x if x <= 180 else 360 - x for\n",
    "                                x in psi_mae]))\n",
    "    theta_mae = np.abs(true_theta - pred_theta)\n",
    "    theta_mae = np.mean(np.array([x if x <= 180 else 360 - x for\n",
    "                                  x in theta_mae]))\n",
    "    tau_mae = np.abs(true_tau - pred_tau)\n",
    "    tau_mae = np.mean(np.array([x if x <= 180 else 360 - x for\n",
    "                                x in tau_mae]))\n",
    "\n",
    "    cacn_mae = np.mean(np.abs(true_cacn - pred_cacn))\n",
    "    cnca_mae = np.mean(np.abs(true_cnca - pred_cnca))\n",
    "    ncac_mae = np.mean(np.abs(true_ncac - pred_ncac))\n",
    "\n",
    "    cn_mae = np.mean(np.abs(true_cn - pred_cn))\n",
    "    nca_mae = np.mean(np.abs(true_nca - pred_nca))\n",
    "    cac_mae = np.mean(np.abs(true_cac - pred_cac))\n",
    "\n",
    "    # Notify of model predictive capability based on MAE values\n",
    "    divider = '*' * 100\n",
    "    print(f'''\n",
    "\\n{divider}\n",
    "\\nDihedral Angle MAE Values\\n\n",
    "\\nPhi MAE:\\t\\t{phi_mae}\n",
    "\\nPsi MAE:\\t\\t{psi_mae}\n",
    "\\nTheta MAE:\\t\\t{theta_mae}\n",
    "\\nTau MAE:\\t\\t{tau_mae}\n",
    "\\n{divider}\n",
    "\\nAtom Angle MAE Values\\n\n",
    "\\nCACN MAE:\\t\\t{cacn_mae}\n",
    "\\nCNCA MAE:\\t\\t{cnca_mae}\n",
    "\\nNCAC MAE:\\t\\t{ncac_mae}\n",
    "\\n{divider}\n",
    "\\nAtom Distance MAE Values\\n\n",
    "\\nCN MAE:\\t\\t\\t{cn_mae}\n",
    "\\nNCA MAE:\\t\\t{nca_mae}\n",
    "\\nCAC MAE:\\t\\t{cac_mae}\n",
    "\\n{divider}\n",
    "    ''')\n",
    "\n",
    "    return model, target_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_model(training_vars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_file_dir, pssm_scaler, pp_scaler,\n",
    "            target_scaler, model, fasta):\n",
    "    \"\"\"\n",
    "    Loads data matrix from 'test_file_dir' for prediction of corresponding\n",
    "    sine and cosine of dihedral angles, bond angles and distances.\n",
    "    Predictions are then used to generate a structure matrix to be used with\n",
    "    NERF to generate protein structure.\n",
    "\n",
    "    Args:\n",
    "        test_file_dir: directory for loading in data for prediction.\n",
    "        pssm_scaler: scaler used on PSSM's of full population for scaling of\n",
    "            test data.\n",
    "        pp_scaler: scaler used on physical properties of full population for\n",
    "            scaling of test data.\n",
    "        model: pretrained LSTM model for prediction of angles and distances.\n",
    "\n",
    "    Returns:\n",
    "        numpy array: matrix of values used by NERF for structure generation.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load data matrix for angle and distance prediction\n",
    "    test_data = np.loadtxt(test_file_dir)\n",
    "\n",
    "    # Scale relevant columns based on full population statistics\n",
    "    test_data[:, :20] = pssm_scaler.transform(test_data[:, :20])\n",
    "    test_data[:, 31:39] = pp_scaler.transform(test_data[:, 31:39])\n",
    "\n",
    "    # Reshape data for LSTM training\n",
    "    test_data = test_data.reshape(test_data.shape[0], 1, test_data.shape[1])\n",
    "\n",
    "    # Save predictions for test_data in 'pred' var\n",
    "    pred = model.predict(test_data)\n",
    "\n",
    "    # Set variables for sine and cosine of dihedral angles\n",
    "    sin_phi = pred[:, 0]\n",
    "    cos_phi = pred[:, 1]\n",
    "    sin_psi = pred[:, 2]\n",
    "    cos_psi = pred[:, 3]\n",
    "    sin_theta = pred[:, 4]\n",
    "    cos_theta = pred[:, 5]\n",
    "    sin_tau = pred[:, 6]\n",
    "    cos_tau = pred[:, 7]\n",
    "\n",
    "    # Set variables for predicted values\n",
    "    pred_phi = np.arctan2(sin_phi, cos_phi) * 180 / np.pi\n",
    "    pred_psi = np.arctan2(sin_psi, cos_psi) * 180 / np.pi\n",
    "    pred_theta = np.arctan2(sin_theta, cos_theta) * 180 / np.pi\n",
    "    pred_tau = np.arctan2(sin_tau, cos_tau) * 180 / np.pi\n",
    "    unscaled_features = target_scaler.inverse_transform(pred[:, 8:])\n",
    "    pred_cacn = unscaled_features[:, 0]\n",
    "    pred_cnca = unscaled_features[:, 1]\n",
    "    pred_ncac = unscaled_features[:, 2]\n",
    "    pred_cn = unscaled_features[:, 3]\n",
    "    pred_nca = unscaled_features[:, 4]\n",
    "    pred_cac = unscaled_features[:, 5]\n",
    "\n",
    "    # Set dictionary to map 1 letter residues to their 3 letter codes for NERF\n",
    "    map_aminos = {\n",
    "        'A': 'ALA',\n",
    "        'R': 'ARG',\n",
    "        'N': 'ASN',\n",
    "        'D': 'ASP',\n",
    "        'C': 'CYS',\n",
    "        'E': 'GLU',\n",
    "        'Q': 'GLN',\n",
    "        'G': 'GLY',\n",
    "        'H': 'HIS',\n",
    "        'I': 'ILE',\n",
    "        'L': 'LEU',\n",
    "        'K': 'LYS',\n",
    "        'M': 'MET',\n",
    "        'F': 'PHE',\n",
    "        'P': 'PRO',\n",
    "        'S': 'SER',\n",
    "        'T': 'THR',\n",
    "        'W': 'TRP',\n",
    "        'Y': 'TYR',\n",
    "        'V': 'VAL'\n",
    "    }\n",
    "\n",
    "    # Create structure data based on layout needed for NERF execution\n",
    "    structure_data = np.hstack((\n",
    "        np.repeat('A', len(fasta)).reshape(-1, 1),\n",
    "        np.arange(1, len(fasta) + 1).reshape(-1, 1),\n",
    "        np.array([map_aminos[aa] for aa in fasta]).reshape(-1, 1),\n",
    "        pred_phi.reshape(-1, 1),\n",
    "        pred_psi.reshape(-1, 1),\n",
    "        np.repeat(180, len(fasta)).reshape(-1, 1),\n",
    "        pred_cacn.reshape(-1, 1),\n",
    "        pred_cnca.reshape(-1, 1),\n",
    "        pred_ncac.reshape(-1, 1),\n",
    "        pred_cn.reshape(-1, 1),\n",
    "        pred_nca.reshape(-1, 1),\n",
    "        pred_cac.reshape(-1, 1)\n",
    "    ))\n",
    "\n",
    "    # Save structure data to specified directory for NERF structure generation\n",
    "    return structure_data, np.round(pred_theta, 2), np.round(pred_tau, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict(test_file_dir, pssm_scaler, pp_scaler,\n",
    "#             target_scaler, model, fasta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_angles(structure_data, pred_theta, pred_tau, file_loc, target, fasta):\n",
    "    \"\"\"\n",
    "    Creates and saves Dihedral angle plots and generates an excel document\n",
    "    which shows sequential residues in the protein chain and corresponding\n",
    "    dihedral angle values.\n",
    "\n",
    "    Args:\n",
    "        structure_data: text document with predicted dihedral angle values.\n",
    "        pred_tau: predicted tau dihedral angle values.\n",
    "        file_loc: location to save plot figures and excel document.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables for dihedral angle values\n",
    "    pred_phi = np.round(structure_data[:, 3].astype(float), 2)\n",
    "    pred_psi = np.round(structure_data[:, 4].astype(float), 2)\n",
    "    pred_cacn = np.round(structure_data[:, 6].astype(float), 2)\n",
    "    pred_cnca = np.round(structure_data[:, 7].astype(float), 2)\n",
    "    pred_ncac = np.round(structure_data[:, 8].astype(float), 2)\n",
    "    pred_cn = np.round(structure_data[:, 9].astype(float), 2)\n",
    "    pred_nca = np.round(structure_data[:, 10].astype(float), 2)\n",
    "    pred_cac = np.round(structure_data[:, 11].astype(float), 2)\n",
    "\n",
    "    # Create dict for naming and value iteration\n",
    "    dihedral_dict = {\n",
    "        'Phi': pred_phi,\n",
    "        'Psi': pred_psi,\n",
    "        'Tau': pred_tau\n",
    "    }\n",
    "\n",
    "    # Iterate over each dihedral angle for plotting\n",
    "    for dihedral_angle in dihedral_dict.keys():\n",
    "        angles = dihedral_dict[dihedral_angle]\n",
    "        x = np.arange(0, len(angles))\n",
    "        y = angles\n",
    "        steps = int(len(angles)/100) * 10 if int(len(angles)/100) else 10\n",
    "        width = int(len(angles) / 6) if int(len(angles) / 6) > 100 else 100\n",
    "        plt.figure(figsize=(width, 40))\n",
    "        plt.plot(x, y, c='k', linewidth=6)\n",
    "        plt.title(f'{target} {dihedral_angle} by Residue', fontsize=60)\n",
    "        plt.xlabel('Residue', fontsize=60)\n",
    "        plt.ylabel(f'{dihedral_angle}', fontsize=60, rotation=0)\n",
    "        plt.xticks(np.arange(0, len(angles), steps), fontsize=30)\n",
    "        plt.yticks(np.arange(-180, 181, 30), fontsize=30)\n",
    "        plot_name = f'{target}_{dihedral_angle}_Plot'\n",
    "        plt.grid(linewidth=1)\n",
    "        plt.savefig(os.path.join(file_loc, plot_name), bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    # Plot the Phi/Psi distribution for the predicted target\n",
    "    plt.figure(figsize=(40, 40))\n",
    "    plt.scatter(\n",
    "        pred_phi,\n",
    "        pred_psi,\n",
    "        s=196,\n",
    "        c='k',\n",
    "        linewidth=1.9,\n",
    "        edgecolors='w'\n",
    "    )\n",
    "    plt.title(f'{target} Phi/Psi Distribution', fontsize=60)\n",
    "    plt.xlabel('Φ', fontsize=30)\n",
    "    plt.ylabel('Ψ', fontsize=30, rotation=0)\n",
    "    plt.xticks(np.arange(-180, 181, 30), fontsize=30)\n",
    "    plt.yticks(np.arange(-180, 181, 30), fontsize=30)\n",
    "    plot_name = f'{target}_Phi_Psi_Distribution'\n",
    "    plt.grid(linewidth=1)\n",
    "    plt.savefig(os.path.join(file_loc, plot_name), bbox_inches='tight')\n",
    "    plt.clf()\n",
    "\n",
    "    # Create numpy array with fasta residues and their corresponding dihedrals\n",
    "    angle_info = np.hstack((\n",
    "        fasta.reshape(-1, 1),\n",
    "        pred_phi.reshape(-1, 1),\n",
    "        pred_psi.reshape(-1, 1),\n",
    "        pred_theta.reshape(-1, 1),\n",
    "        pred_tau.reshape(-1, 1),\n",
    "        pred_cacn.reshape(-1, 1),\n",
    "        pred_cnca.reshape(-1, 1),\n",
    "        pred_ncac.reshape(-1, 1),\n",
    "        pred_cn.reshape(-1, 1),\n",
    "        pred_nca.reshape(-1, 1),\n",
    "        pred_cac.reshape(-1, 1)\n",
    "    ))\n",
    "\n",
    "    # Create dataframe with dihedral information for saving into an excel file\n",
    "    df = pd.DataFrame(\n",
    "        data=angle_info,\n",
    "        columns=['Residue', 'Phi', 'Psi', 'Theta', 'Tau', 'CACN',\n",
    "                 'CNCA', 'NCAC', 'D:C-N', 'D:N-CA', 'D:CA-C']\n",
    "    )\n",
    "    filename = f'{target}_Dihedrals.xlsx'\n",
    "    df.to_excel(os.path.join(file_loc, filename), index=False)\n",
    "\n",
    "    # Autofit column widths with openpyxl\n",
    "    wb = openpyxl.load_workbook(os.path.join(file_loc, filename))\n",
    "    ws = wb.active\n",
    "    for column_cells in ws.columns:\n",
    "        length = max(len(cell.value) for cell in column_cells)\n",
    "        ws.column_dimensions[column_cells[0].column_letter].width = length + 3\n",
    "    wb.save(os.path.join(file_loc, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fasta_seq(target_dir, target):\n",
    "    '''\n",
    "    Reads in fasta sequence for target specified\n",
    "    '''\n",
    "    # Read fasta text file and save lines\n",
    "    with open(fr'{target_dir}/{target}.fasta', 'r') as f:\n",
    "        fasta_info = f.readlines()\n",
    "\n",
    "    # Extract fasta sequence from second line of file and return array\n",
    "    fasta_seq = fasta_info[1].strip()\n",
    "    fasta_arr = np.array([aa for aa in fasta_seq])\n",
    "\n",
    "    return fasta_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # Set location of directory with protein structure prediction data\n",
    "    file_loc = r'/home/jobc/J/LSTM/data_files'\n",
    "    #file_loc = r'C:/Users/Pradeep Kumar Yadav/Documents/LSTM/LSTM/complete'\n",
    "    #model_var_loc = r'/home/jobc/J/LSTM/model_vars'\n",
    "    model_var_loc = r'C:/Users/Pradeep Kumar Yadav/Documents/LSTM/LSTM/model_vars'\n",
    "    # target_train_file = 'Clean_Training.pbz2' #fr'{TARGET}_Training.pbz2'\n",
    "\n",
    "    # # Load numpy array of feature and target data from predefined file\n",
    "    # with bz2.BZ2File(os.path.join(file_loc, target_train_file), 'rb') as f:\n",
    "    #     data = pickle.load(f)\n",
    "\n",
    "    # # Run data engineering processes for optimal model training and pred\n",
    "    # data = data_augmentation(data)\n",
    "\n",
    "    # # Create training variables for model training and evaluation\n",
    "    # training_vars = split_data(data)\n",
    "\n",
    "    # # Generate model for future predictions\n",
    "    # model, target_scaler = make_model(training_vars)\n",
    "    \n",
    "    # Load vars\n",
    "    model = tf.keras.models.load_model(os.path.join(model_var_loc,\n",
    "                                                    'best_model.h5'))\n",
    "    target_scaler = joblib.load(os.path.join(model_var_loc, 'target_scaler'))\n",
    "    pssm_scaler = joblib.load(os.path.join(model_var_loc, 'pssm_scaler'))\n",
    "    pp_scaler = joblib.load(os.path.join(model_var_loc, 'pp_scaler'))\n",
    "\n",
    "    targets = [f.split('_')[0] for f in os.listdir(file_loc) if\n",
    "               'final_input' in f]\n",
    "\n",
    "    for target in targets:\n",
    "        fasta = get_fasta_seq(file_loc, target)\n",
    "\n",
    "        # Predict desired protein chain and create structure matrix for NERF\n",
    "        structure_data, pred_theta, pred_tau = predict(\n",
    "            fr'{file_loc}/{target}_final_input.npy',\n",
    "            # training_vars['pssm_scaler'],\n",
    "            # training_vars['pp_scaler'],\n",
    "            pssm_scaler,\n",
    "            pp_scaler,\n",
    "            target_scaler,\n",
    "            model,\n",
    "            fasta\n",
    "        )\n",
    "\n",
    "        # Create plot and excel files for analysis of prediction\n",
    "        plot_angles(structure_data, pred_theta, pred_tau,\n",
    "                    file_loc, target, fasta)\n",
    "\n",
    "        # Save structure matrix in text file for NERF structure generation\n",
    "        np.savetxt(\n",
    "            os.path.join(file_loc, fr'{target}_structure_data.txt'),\n",
    "            structure_data,\n",
    "            fmt='%s'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
